{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para rodar:\n",
    "\n",
    "1. Crie um .env com a variável DEEPGRAM_API_KEY, disponível no google drive em um documento chamado keys\n",
    "2. Instale - pyaudio, deepgram-sdk, python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgram import DeepgramClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "key = load_dotenv()\n",
    "# Create a Deepgram client using the DEEPGRAM_API_KEY from environment variables\n",
    "deepgram = DeepgramClient(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WebSocketException in LiveClient.start: server rejected WebSocket connection: HTTP 401\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LiveClient' object has no attribute '_keep_alive_thread'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m microphone\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Indicate that we've finished\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mdg_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Insper/Semestre 5/Startup/simulai/env/lib/python3.11/site-packages/deepgram/clients/live/v1/client.py:477\u001b[0m, in \u001b[0;36mLiveClient.finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# stop the threads\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mverbose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelling tasks...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keep_alive_thread\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keep_alive_thread\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mnotice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing thread joined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LiveClient' object has no attribute '_keep_alive_thread'"
     ]
    }
   ],
   "source": [
    "from deepgram import LiveTranscriptionEvents, LiveOptions, Microphone\n",
    "from pyaudio import *\n",
    "import json\n",
    "\n",
    "dg_connection = deepgram.listen.live.v(\"1\")\n",
    "\n",
    "def on_open(self, open, **kwargs):\n",
    "    print(f\"\\n\\n{open}\\n\\n\")\n",
    "\n",
    "def on_message(self, result, **kwargs):\n",
    "    sentence = result.channel.alternatives[0].transcript\n",
    "    if len(sentence) == 0:\n",
    "        return\n",
    "    print(f\"speaker: {sentence}\")\n",
    "\n",
    "def on_metadata(self, metadata, **kwargs):\n",
    "    print(f\"\\n\\n{metadata}\\n\\n\")\n",
    "\n",
    "def on_speech_started(self, speech_started, **kwargs):\n",
    "    print(f\"\\n\\n{speech_started}\\n\\n\")\n",
    "\n",
    "def on_utterance_end(self, utterance_end, **kwargs):\n",
    "    print(f\"\\n\\n{utterance_end}\\n\\n\")\n",
    "\n",
    "def on_error(self, error, **kwargs):\n",
    "    print(f\"\\n\\n{error}\\n\\n\")\n",
    "\n",
    "def on_close(self, close, **kwargs):\n",
    "    print(f\"\\n\\n{close}\\n\\n\")\n",
    "\n",
    "dg_connection.on(LiveTranscriptionEvents.Open, on_open)\n",
    "dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n",
    "dg_connection.on(LiveTranscriptionEvents.Metadata, on_metadata)\n",
    "dg_connection.on(LiveTranscriptionEvents.SpeechStarted, on_speech_started)\n",
    "dg_connection.on(LiveTranscriptionEvents.UtteranceEnd, on_utterance_end)\n",
    "dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n",
    "dg_connection.on(LiveTranscriptionEvents.Close, on_close)\n",
    "\n",
    "options: LiveOptions = LiveOptions(\n",
    "    model=\"nova-2\",\n",
    "    punctuate=True,\n",
    "    language=\"en-US\", # Change to pt-BR for Brazilian Portuguese\n",
    "    encoding=\"linear16\",\n",
    "    channels=1,\n",
    "    sample_rate=16000,\n",
    "    # To get UtteranceEnd, the following must be set:\n",
    "    interim_results=True,\n",
    "    utterance_end_ms=\"1000\",\n",
    "    vad_events=True,\n",
    ")\n",
    "dg_connection.start(options)\n",
    "\n",
    "# create microphone\n",
    "microphone = Microphone(dg_connection.send)\n",
    "\n",
    "# start microphone\n",
    "microphone.start()\n",
    "\n",
    "# wait until finished\n",
    "input(\"Press Enter to stop recording...\\n\\n\")\n",
    "\n",
    "# Wait for the microphone to close\n",
    "microphone.finish()\n",
    "\n",
    "# Indicate that we've finished\n",
    "dg_connection.finish()\n",
    "\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
